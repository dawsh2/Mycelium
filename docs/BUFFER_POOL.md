# Buffer Pool Design - Zero-Allocation Network I/O

**Status**: Design Phase
**Priority**: Optimize after profiling shows network allocation bottleneck
**Estimated Impact**: ~60% reduction in allocation overhead (~300ns per message)

---

## Problem Statement

Network transports currently perform **3 allocations + 1 copy per message**:

```rust
// stream.rs - Current implementation
let mut tlv_bytes = Vec::with_capacity(HEADER_SIZE + payload_len);  // ALLOC 1
tlv_bytes.extend_from_slice(&header_buf);

let mut payload_buf = vec![0u8; payload_len];  // ALLOC 2
stream.read_exact(&mut payload_buf).await?;
tlv_bytes.extend_from_slice(&payload_buf);  // COPY

let frame = RawFrame {
    type_id,
    bytes: Arc::new(bytes),  // ALLOC 3: Arc wrapper
};
```

**Overhead**: ~500ns per message (200-500ns for allocations + copy)

---

## Solution: TLV-Inferred Buffer Pool

### Key Insight

**Message sizes are known at compile time from TLV definitions**, so buffer sizes can be automatically inferred:

```yaml
# contracts.yaml
messages:
  - name: SwapEvent
    fields:
      - name: pool_address
        type: Address      # 20 bytes
      - name: amount_in
        type: uint256      # 32 bytes
      - name: amount_out
        type: uint256      # 32 bytes
    # Total: 84 bytes → round up to 128 byte buffer class
```

**No hardcoded configuration needed!**

---

## Architecture

### 1. Compile-Time Size Inference

The TLV codegen calculates max message sizes and generates pool configuration:

```rust
// Generated by codegen from contracts.yaml
pub struct BufferPoolConfig {
    size_classes: [
        (128, 256),   // SwapEvent (84 bytes)  → 128 byte buffers, 256 pool capacity
        (256, 128),   // PoolStateUpdate (180 bytes) → 256 byte buffers, 128 capacity
        (1024, 64),   // LargeMessage (800 bytes) → 1024 byte buffers, 64 capacity
    ]
}
```

**User never sees this** - it's entirely derived from their message definitions.

### 2. Service-Level Declaration

Users declare what messages their service handles:

```toml
# config.toml
[service.polygon-adapter]
messages = ["SwapEvent", "PoolStateUpdate"]
buffer_pool_enabled = true  # Optional: defaults to true
```

**That's it!** The pool configuration is automatically generated from the TLV definitions.

### 3. Runtime API

```rust
// mycelium-transport internally creates pool based on service config
let pool = BufferPool::from_service_config(&config);

// Transparent to user - codec uses pooled buffers automatically
let (type_id, buffer) = read_frame_pooled(&mut stream, &pool).await?;
// Buffer returns to pool on drop
```

---

## Implementation Plan

### Phase 1: Codegen Enhancement (2-3 days)

Update `scripts/codegen.py` to analyze message sizes:

```python
# codegen.py additions
def calculate_message_size(message_def):
    """Calculate max size for a message from field definitions."""
    size = 0
    for field in message_def['fields']:
        size += TYPE_SIZES[field['type']]
    return size

def generate_buffer_pool_config(messages):
    """Generate buffer pool configuration from message definitions."""
    size_classes = {}
    for msg in messages:
        size = calculate_message_size(msg)
        buffer_class = next_power_of_two(max(size, 128))  # Min 128 bytes

        if buffer_class not in size_classes:
            # Heuristic: More small messages, fewer large
            capacity = 1024 // (buffer_class // 128)
            size_classes[buffer_class] = capacity

    return size_classes
```

**Output**:
```rust
// generated.rs
impl SwapEvent {
    pub const MAX_SIZE: usize = 84;
    pub const BUFFER_CLASS: usize = 128;
}

pub fn create_buffer_pool() -> BufferPool {
    BufferPool::builder()
        .with_size_class(128, 256)  // For SwapEvent, etc.
        .with_size_class(256, 128)  // For PoolStateUpdate, etc.
        .build()
}
```

### Phase 2: Buffer Pool Implementation (1-2 days)

```rust
// mycelium-transport/src/buffer_pool.rs
pub struct BufferPool {
    pools: Arc<Mutex<HashMap<usize, Vec<Vec<u8>>>>>,
    config: BufferPoolConfig,
}

impl BufferPool {
    pub fn acquire(&self, size: usize) -> PooledBuffer {
        // Find smallest size class >= size
        // Reuse buffer if available, allocate if needed
    }
}

pub struct PooledBuffer {
    buffer: Vec<u8>,
    pool: BufferPool,
    size_class: usize,
}

impl Drop for PooledBuffer {
    fn drop(&mut self) {
        // Return buffer to pool
        self.pool.return_buffer(self.buffer, self.size_class);
    }
}
```

### Phase 3: Codec Integration (1 day)

```rust
// codec.rs
pub async fn read_frame_pooled(
    stream: &mut impl AsyncRead,
    pool: &BufferPool,
) -> Result<(u16, PooledBuffer)> {
    // Read TLV header
    let (type_id, length) = read_header(stream).await?;

    // Acquire pooled buffer (reuses allocation)
    let mut buffer = pool.acquire(length);
    stream.read_exact(&mut buffer[..length]).await?;

    Ok((type_id, buffer))  // Buffer returns to pool on drop
}
```

---

## User Experience

### Before (Manual Configuration - AVOID THIS)

```toml
[buffer_pool]
size_classes = [128, 256, 1024, 4096]  # User has to figure this out!
capacities = [256, 128, 64, 32]        # And this!
```

**Problems**:
- User has no idea what sizes to use
- Wrong sizes = wasted memory or poor performance
- Maintenance burden when adding new message types

### After (Automatic - THIS IS THE GOAL)

```toml
[service.my-service]
messages = ["SwapEvent", "PoolStateUpdate"]  # Just declare what you handle
buffer_pool_enabled = true  # Optional flag
```

**Benefits**:
- Zero configuration
- Automatically optimal based on actual message sizes
- Add new message type? Pool auto-adjusts
- Type-safe - can't reference non-existent message types

---

## Performance Expectations

### Current (Without Pool)
- **3 allocations**: Vec (header+payload), Vec (payload), Arc
- **1 copy**: payload into combined buffer
- **~500ns overhead per message**

### With Buffer Pool
- **1 allocation**: Arc (payload Arc only, buffers reused)
- **1 copy**: still need to copy from socket into buffer
- **~200ns overhead per message**
- **60% reduction in allocation overhead**

### When Does This Matter?

**Matters for**:
- High message volume (>10k messages/sec per connection)
- Sub-millisecond latency requirements
- Memory-constrained environments

**Doesn't matter for**:
- Strategy latency >> allocation overhead (typical solo trader)
- Low message volume (<1k messages/sec)
- When network I/O dominates (10-50μs per message)

---

## Implementation Priority

### Current Recommendation: **DEFER**

Reasons to wait:
1. **Premature optimization**: Current bottlenecks likely elsewhere (strategy logic, Redis, etc.)
2. **Complexity**: Adds lifecycle management, debugging complexity
3. **Marginal gains**: 300ns per message is noise compared to microsecond+ strategy latency

### When to Implement

Implement when **profiling** shows:
- Network allocation is >5% of total latency
- You're processing >10k messages/sec and latency is critical
- Memory allocation is causing GC pauses (rare in Rust)

### Pragmatic Approach

1. ✅ **Now**: Design documented (this file)
2. ⏭️ **Next**: Build trading system, profile it
3. ⏭️ **Later**: If profiling shows bottleneck, implement buffer pool
4. ⏭️ **Optimize**: Tune pool sizes based on real workload

---

## Alternative: Buffer Pool v2 (Ring Buffer)

If profiling shows buffer pool is needed AND single-threaded performance is critical:

```rust
// Lock-free ring buffer (Linux io_uring style)
pub struct RingBufferPool {
    buffers: Vec<UnsafeCell<Vec<u8>>>,
    head: AtomicUsize,  // Producer index
    tail: AtomicUsize,  // Consumer index
}
```

**Gains**: Eliminate Mutex overhead (~50ns)
**Cost**: Unsafe code, complex, single-producer-single-consumer only

**Recommendation**: Start with simple Mutex-based pool, optimize to ring buffer only if profiling shows Mutex contention.

---

## Testing Strategy

When implementing, test:

1. **Correctness**: Buffer contents not corrupted across reuse
2. **No leaks**: Buffers returned to pool on drop (even on panic)
3. **Capacity limits**: Pool doesn't grow unbounded
4. **Size selection**: Messages routed to correct size class
5. **Performance**: Benchmark with/without pool on realistic workload

---

## Summary

**Design**: TLV codegen automatically infers optimal buffer pool configuration from message definitions.

**User Experience**: Zero configuration - just declare what messages your service handles.

**Priority**: Implement after profiling shows network allocation is a bottleneck.

**Estimated Effort**: 4-6 days implementation + testing

**Performance Impact**: ~60% reduction in allocation overhead, ~300ns per message savings

---

**Last Updated**: 2025-01-03
**Next Review**: After initial trading system profiling
